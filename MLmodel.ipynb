{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070fbfa1-0d7b-494f-8b7f-1102e8481c50",
   "metadata": {},
   "source": [
    "# Dependency Installments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68a56bf-2a8b-4061-97b5-6765a317d551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting git+https://github.com/csebuetnlp/normalizer\n",
      "  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-m5byb7qd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-m5byb7qd\n",
      "  Resolved https://github.com/csebuetnlp/normalizer to commit d80c3c484e1b80268f2b2dfaf7557fe65e34f321\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from normalizer==0.0.1) (2022.10.31)\n",
      "Requirement already satisfied: emoji==1.4.2 in /opt/conda/lib/python3.7/site-packages (from normalizer==0.0.1) (1.4.2)\n",
      "Requirement already satisfied: ftfy==6.0.3 in /opt/conda/lib/python3.7/site-packages (from normalizer==0.0.1) (6.0.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.1.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/csebuetnlp/normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b544f249-226c-47ce-a8a8-012685f6e24a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad5837-3b91-4934-bdba-fee537e9579d",
   "metadata": {},
   "source": [
    "# Data Preprocessing Core Functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b91a75-880c-4543-b862-c9894450c8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from normalizer import normalize\n",
    "\n",
    "filepath = os.path.join(\".\", \"dev.txt\")\n",
    "output_file = os.path.join(\".\", \"dev.jsonl\")\n",
    "with open(filepath) as fp:\n",
    "    lines = fp.readlines()\n",
    "    cnt = 1\n",
    "    all_data = []\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for line in lines:\n",
    "        \n",
    "        # print(\"Line {}: {}\".format(cnt, line.strip()))\n",
    "        line = line.strip()\n",
    "        if line == \"\":\n",
    "            all_data.append({'tokens': tokens, 'tags': tags})\n",
    "            # print(tokens, tags)\n",
    "            tokens = []\n",
    "            tags = []\n",
    "            continue\n",
    "        # words = line\n",
    "        # print(words)\n",
    "        if len(line) == 1:\n",
    "            token = line\n",
    "        else:\n",
    "            token = normalized_text = normalize(\n",
    "                line,\n",
    "                unicode_norm=\"NFKC\",          # type of unicode normalization (default \"NFKC\")\n",
    "                punct_replacement=\"\",       # an optional string or callable for replacing the punctuations (default `None`, i.e. no replacement)\n",
    "                url_replacement=\"\",         # an optional string or callable for replacing the URLS (default `None`, i.e. no replacement)\n",
    "                emoji_replacement=\"\",       # an optional string or callable for replacing the emojis (default `None`, i.e. no replacement)\n",
    "                apply_unicode_norm_last=True  # whether to apply the unicode normalization before or after rule based replacements (default True)        \n",
    "            )\n",
    "        \n",
    "        # print(token)\n",
    "        tokens.append(token)\n",
    "        tags.append('O')\n",
    "        cnt += 1\n",
    "    all_data.append({'tokens': tokens, 'tags': tags})\n",
    "    # print(all_data)\n",
    "        \n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    for item in all_data:\n",
    "        json.dump(item, json_file, ensure_ascii=False)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de1768c-9d2b-4831-a33f-d8c031a870cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readfile(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as reader:\n",
    "        for line in reader:\n",
    "            data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09a061c-8f90-498d-b385-c5f2d0b03904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(\".\", \"dev.jsonl\")\n",
    "train_data = readfile(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "692be970-8f0d-4877-af0e-fb97845abe10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['নিকটতম', 'বিমানবন্দরটি', '(', '১৫৮', 'কিমি', ')', 'রাজীব', 'গান্ধী', 'আন্তর্জাতিক', 'বিমানবন্দর']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "train_data_tokens = []\n",
    "train_data_tags = []\n",
    "for data in train_data:\n",
    "    train_data_tokens = train_data_tokens + data[\"tokens\"]\n",
    "    train_data_tags = train_data_tags+ data['tags']\n",
    "print(train_data_tokens[:10])\n",
    "print(train_data_tags[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a88db22-51d7-4984-8ea9-3a7a5c861a40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>নিকটতম</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>বিমানবন্দরটি</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>১৫৮</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>কিমি</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tokens tags\n",
       "0        নিকটতম    O\n",
       "1  বিমানবন্দরটি    O\n",
       "2             (    O\n",
       "3           ১৫৮    O\n",
       "4          কিমি    O"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {'tokens': train_data_tokens,\n",
    "              'tags': train_data_tags}\n",
    "\n",
    "df = pd.DataFrame.from_dict(word_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f7d5a96-13d6-470a-aaf6-a78d8ef14b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df.tags.values\n",
    "X = df.drop('tags', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a3f2d09-3336-40e4-9ad0-a42762954350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>নিকটতম</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>বিমানবন্দরটি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>১৫৮</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>কিমি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152437</th>\n",
       "      <td>বিজ্ঞাপনগুলি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152438</th>\n",
       "      <td>প্রচার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152439</th>\n",
       "      <td>করা</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152440</th>\n",
       "      <td>শুরু</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152441</th>\n",
       "      <td>করে</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152442 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tokens\n",
       "0             নিকটতম\n",
       "1       বিমানবন্দরটি\n",
       "2                  (\n",
       "3                ১৫৮\n",
       "4               কিমি\n",
       "...              ...\n",
       "152437  বিজ্ঞাপনগুলি\n",
       "152438        প্রচার\n",
       "152439           করা\n",
       "152440          শুরু\n",
       "152441           করে\n",
       "\n",
       "[152442 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "166328cc-3173-4e5f-92b6-7e6d2bc58ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "532db33b-acd6-49df-aab4-4360085b3de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = v.fit_transform(X.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a6b7dc6-2ff3-4bc6-8568-a4ba3869f2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1, random_state=0)\n",
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029c99b-55c9-4751-a06a-949952584cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC, NuSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7f0ec-0ed9-432e-a799-12dfa213df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa71eed-2abc-4eaa-b7b0-95de41813a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1733028-e6c0-420e-9b7a-b3a0699d94f7",
   "metadata": {},
   "source": [
    "## Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aabf38b9-11eb-4106-89d8-965e1bd6fd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 24584 features per sample; expecting 17380",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0ea4e52475f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'model/finalized_model.sav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 273\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 24584 features per sample; expecting 17380"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "loaded_model = pickle.load(open(r'model/finalized_model.sav', 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42a521-7604-4ec5-abc9-e91820d00792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
